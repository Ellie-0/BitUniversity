{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/bitproject.png\" width=\"200\" align=\"left\"> \n",
    "<img src=\"images/data-science.jpg\" width=\"300\" align=\"right\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div align=\"center\">Modeling and Prediction in Data Science</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "## [Recap](#recap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recap <a name=\"recap\"></a>\n",
    "\n",
    "By this point we have covered the following:\n",
    "- Using pandas for advanced data wrangling.  (Week 6)\n",
    "- What is Statistical Anlysis and important methods.  (Week 8)\n",
    "- Visualizing statistical and categorical data using Seaborn.  (Week 9)\n",
    "\n",
    "These are the building blocks of our data science pipeline. But what is the end result of these building blocks? What is at the top of the tower?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the End Result of Data Science?\n",
    "The end result of our project varies for every situation:\n",
    "- For buisnesses business, we would be looking at predictions for future sales (This field probably went crazy as the pandemic hit).\n",
    "- For hospitals it can be classification between patients on the basis of severity.\n",
    "- Since this is a DigitalHistory class we are looking at previous patterns to predict future patterns or to simply classify items in historical datasets (*hypothetical example, bad king, good king*)\n",
    "\n",
    "\n",
    "You might think, 'If i'm studying data science, why am I learning this so late'. The answer is simple. Many people assume taht data science is mostly machine learning and that we mostly build, train and tweak Mahine Learning models. However, the truth is very far from it, most of the time we spend working integrating business/social/research problems into data problems, this is an iterative process which involves collecting data and understanding it by cleaning and transforming it. This process itself is long and requires analytical input, while the Machine Learning implemenation at the end is a very simple process.\n",
    "\n",
    "Even though it's simple, it's vital as it brings our idea/project/goals to a conclusion.\n",
    "\n",
    "Before we get into understanding Machine Learning, lets look into what models are.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Introduction to Models\n",
    "\n",
    "**What is a model?** \n",
    "A model is simply specifying a mathematical relationship that exists between different variables.\n",
    "*For example*:\n",
    "- **Trans Atlantic Slave Trade** - The number of ships that left Liverpool might have a direct correlation with the increase in the number of slaves. Therefore that is a mathematical relationship.\n",
    "- **The Titanic Dataset** - Most of the people who died on the titanic belonged to the lower class cabins. Therefore if a passenger was in the class, the 'chances' of him dying were higher. \n",
    "\n",
    "Other real world examples might be.\n",
    "- You're trying to raise money for your social networking site, you might be able to build a *business model* that takes inputs of 'number of users, 'ad revenue per user' and 'number of employees' and ouputs your annual profit for the next several years. \n",
    "- A cookbook recipe entails a mdoel that relates input like 'number of eaters' and 'hungriness' to quantities of ingredients neded.\n",
    "- If you are looking at historical records of rain in order to predict the next drought in a region, 'yearly rain','temperature data' and 'drought years' can help you observe the drought patterns and how they correlate with change in temperatures and rainfall decline.\n",
    "\n",
    "Overall the 'model' is based on simple mathematical relationships.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Machine Learning\n",
    "\n",
    "If you have heard this buzz word around you, chances are everyone has given a different definition. *In our case machine learning refers to creating and using models that are learned from data.*\n",
    "This can also be reffered to as *predictive modeling* or *data mining*, Machine learning is just a simple term to identify them.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Our goal when working with historical records is to develop models that we can use to predict various outcomes for new data.\n",
    "-\n",
    "-\n",
    "-\n",
    "\n",
    "\n",
    "For this course we ill be looking at supervised modeling:\n",
    "\n",
    "### What is supervised modeling?\n",
    "This modeling refers to cases where the sets of data we have are labelled with the correct answers to learn from. We will dive into this more as we go down the line but keep this definition in mind for now.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the next exercises we will be going step by step from model to machine learning.\n",
    "\n",
    "### Case Study:\n",
    "Your friend has made millions of dollars speculating on real estate. He has offered to become business partners with you because of your itnerest in data science. He'll supply the money and you'll supply models that predict how much various houses are worth.\n",
    "\n",
    "You ask your friend how he's predicted real estate values in the past. **Hey says it is just intuition**. However, more questioning reveals that he has identified price patterns from houses he has seen in the past, and he uses those patterns to make predictions for new houses he is considering\n",
    "\n",
    "Many Machine learning models work in a very similar manner.\n",
    "\n",
    "For this case study lets look into one called ***Decision Tree***.\n",
    "\n",
    "*Note: There are fancier models out there which might give you better predictions. But in order to understand the basic concepts we will look into decision Trees. This is because Decision Trees are easy to undestand and are one of the foundational building blocks of most models in data science.*\n",
    "\n",
    "### What is a Decision Tree?\n",
    "\n",
    "For starters lets look at a Simple Decision Tree.\n",
    "\n",
    "![DecisionTree-1.png](images/DecisionTree-1.png)\n",
    "\n",
    "For now we only have two categories. The predicted price for any house under considersation is the average price of the house in the same category.\n",
    "\n",
    "We can use data to decide how to break the houses into two groups, and then again to determine the predicted price in each group.\n",
    "\n",
    "- The step of capturing patterns is called **fitting** or **training** the model. \n",
    "- The data used to **fit** the model is called the **training data**.\n",
    "\n",
    "### Improving the Decision Tree?\n",
    "\n",
    "![DecisionTree-2.png](images/DecisionTree-2.png)\n",
    "\n",
    "**Looking at the Decision Trees above, which one do you think is more likely to result from fitting the real estate training data?**\n",
    "\n",
    "The one on the left (Decision Tree 1) makes more sense, because it captures the reality that houses with more bedrooms tend to sell at higher prices than houses with fewer bedrooms.\n",
    "\n",
    "However, this model does have a short coming, **can you guess what it might be?**\n",
    "\n",
    "The biggest shortcoming is that it does not capture most factors affecting homep price, like number of bathrooms, lot size, location etc.\n",
    "\n",
    "You can capture more factors using a tree that has more *splits*.\n",
    "\n",
    "\n",
    "\n",
    "This way we can predict the price of any house by tracing through the decision tree, always picking the path corresponding to that house's characteristic. The predicted price for the house is at the bottom of the tree. The point at the bottom where we make a prediction is called a **leaf**\n",
    "\n",
    "The splits and values at the leaves will be determined by the data so\n",
    "lets check out the data now.\n",
    "\n",
    "we will first load our data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examining our Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Price</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Postcode</th>\n",
       "      <th>Bedroom2</th>\n",
       "      <th>Bathroom</th>\n",
       "      <th>Car</th>\n",
       "      <th>Landsize</th>\n",
       "      <th>BuildingArea</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>Lattitude</th>\n",
       "      <th>Longtitude</th>\n",
       "      <th>Propertycount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>13580.000000</td>\n",
       "      <td>1.358000e+04</td>\n",
       "      <td>13580.000000</td>\n",
       "      <td>13580.000000</td>\n",
       "      <td>13580.000000</td>\n",
       "      <td>13580.000000</td>\n",
       "      <td>13518.000000</td>\n",
       "      <td>13580.000000</td>\n",
       "      <td>7130.000000</td>\n",
       "      <td>8205.000000</td>\n",
       "      <td>13580.000000</td>\n",
       "      <td>13580.000000</td>\n",
       "      <td>13580.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>2.937997</td>\n",
       "      <td>1.075684e+06</td>\n",
       "      <td>10.137776</td>\n",
       "      <td>3105.301915</td>\n",
       "      <td>2.914728</td>\n",
       "      <td>1.534242</td>\n",
       "      <td>1.610075</td>\n",
       "      <td>558.416127</td>\n",
       "      <td>151.967650</td>\n",
       "      <td>1964.684217</td>\n",
       "      <td>-37.809203</td>\n",
       "      <td>144.995216</td>\n",
       "      <td>7454.417378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.955748</td>\n",
       "      <td>6.393107e+05</td>\n",
       "      <td>5.868725</td>\n",
       "      <td>90.676964</td>\n",
       "      <td>0.965921</td>\n",
       "      <td>0.691712</td>\n",
       "      <td>0.962634</td>\n",
       "      <td>3990.669241</td>\n",
       "      <td>541.014538</td>\n",
       "      <td>37.273762</td>\n",
       "      <td>0.079260</td>\n",
       "      <td>0.103916</td>\n",
       "      <td>4378.581772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.500000e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1196.000000</td>\n",
       "      <td>-38.182550</td>\n",
       "      <td>144.431810</td>\n",
       "      <td>249.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.500000e+05</td>\n",
       "      <td>6.100000</td>\n",
       "      <td>3044.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>1940.000000</td>\n",
       "      <td>-37.856822</td>\n",
       "      <td>144.929600</td>\n",
       "      <td>4380.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>9.030000e+05</td>\n",
       "      <td>9.200000</td>\n",
       "      <td>3084.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>440.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>1970.000000</td>\n",
       "      <td>-37.802355</td>\n",
       "      <td>145.000100</td>\n",
       "      <td>6555.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.330000e+06</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>3148.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>651.000000</td>\n",
       "      <td>174.000000</td>\n",
       "      <td>1999.000000</td>\n",
       "      <td>-37.756400</td>\n",
       "      <td>145.058305</td>\n",
       "      <td>10331.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000e+06</td>\n",
       "      <td>48.100000</td>\n",
       "      <td>3977.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>433014.000000</td>\n",
       "      <td>44515.000000</td>\n",
       "      <td>2018.000000</td>\n",
       "      <td>-37.408530</td>\n",
       "      <td>145.526350</td>\n",
       "      <td>21650.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Rooms         Price      Distance      Postcode      Bedroom2  \\\n",
       "count  13580.000000  1.358000e+04  13580.000000  13580.000000  13580.000000   \n",
       "mean       2.937997  1.075684e+06     10.137776   3105.301915      2.914728   \n",
       "std        0.955748  6.393107e+05      5.868725     90.676964      0.965921   \n",
       "min        1.000000  8.500000e+04      0.000000   3000.000000      0.000000   \n",
       "25%        2.000000  6.500000e+05      6.100000   3044.000000      2.000000   \n",
       "50%        3.000000  9.030000e+05      9.200000   3084.000000      3.000000   \n",
       "75%        3.000000  1.330000e+06     13.000000   3148.000000      3.000000   \n",
       "max       10.000000  9.000000e+06     48.100000   3977.000000     20.000000   \n",
       "\n",
       "           Bathroom           Car       Landsize  BuildingArea    YearBuilt  \\\n",
       "count  13580.000000  13518.000000   13580.000000   7130.000000  8205.000000   \n",
       "mean       1.534242      1.610075     558.416127    151.967650  1964.684217   \n",
       "std        0.691712      0.962634    3990.669241    541.014538    37.273762   \n",
       "min        0.000000      0.000000       0.000000      0.000000  1196.000000   \n",
       "25%        1.000000      1.000000     177.000000     93.000000  1940.000000   \n",
       "50%        1.000000      2.000000     440.000000    126.000000  1970.000000   \n",
       "75%        2.000000      2.000000     651.000000    174.000000  1999.000000   \n",
       "max        8.000000     10.000000  433014.000000  44515.000000  2018.000000   \n",
       "\n",
       "          Lattitude    Longtitude  Propertycount  \n",
       "count  13580.000000  13580.000000   13580.000000  \n",
       "mean     -37.809203    144.995216    7454.417378  \n",
       "std        0.079260      0.103916    4378.581772  \n",
       "min      -38.182550    144.431810     249.000000  \n",
       "25%      -37.856822    144.929600    4380.000000  \n",
       "50%      -37.802355    145.000100    6555.000000  \n",
       "75%      -37.756400    145.058305   10331.000000  \n",
       "max      -37.408530    145.526350   21650.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = 'data/melb_data.csv'\n",
    "\n",
    "# read the data and store data in DataFrame titles melbourne_data\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13580 entries, 0 to 13579\n",
      "Data columns (total 21 columns):\n",
      "Suburb           13580 non-null object\n",
      "Address          13580 non-null object\n",
      "Rooms            13580 non-null int64\n",
      "Type             13580 non-null object\n",
      "Price            13580 non-null float64\n",
      "Method           13580 non-null object\n",
      "SellerG          13580 non-null object\n",
      "Date             13580 non-null object\n",
      "Distance         13580 non-null float64\n",
      "Postcode         13580 non-null float64\n",
      "Bedroom2         13580 non-null float64\n",
      "Bathroom         13580 non-null float64\n",
      "Car              13518 non-null float64\n",
      "Landsize         13580 non-null float64\n",
      "BuildingArea     7130 non-null float64\n",
      "YearBuilt        8205 non-null float64\n",
      "CouncilArea      12211 non-null object\n",
      "Lattitude        13580 non-null float64\n",
      "Longtitude       13580 non-null float64\n",
      "Regionname       13580 non-null object\n",
      "Propertycount    13580 non-null float64\n",
      "dtypes: float64(12), int64(1), object(8)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting Data for Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with most of the datasets, there are too many variables to wrap our heads around. So, how do we trim this huge dataset to something we can work with? As with the way we modified our previous datasets\n",
    "\n",
    "We will start picking variables using our intuition (or gut). When we work with more complicated datasets, there are statistical techniques that automatically prioritize variables.\n",
    "\n",
    "To Choose the variables/columns, we will print out the columns in the dataset.\n",
    "\n",
    "the ```df.columns``` property is our go to method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Suburb', 'Address', 'Rooms', 'Type', 'Price', 'Method', 'SellerG',\n",
       "       'Date', 'Distance', 'Postcode', 'Bedroom2', 'Bathroom', 'Car',\n",
       "       'Landsize', 'BuildingArea', 'YearBuilt', 'CouncilArea', 'Lattitude',\n",
       "       'Longtitude', 'Regionname', 'Propertycount'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the Prediction Target\n",
    "If you remember from pervious lessons we can pull out a variable with **dot-notation**. This single column is stored in a Series, which is a DataFrame but with only 1 column.\n",
    "\n",
    "We will use the dot notation to select the column we want to predict, which is called the **prediction target**. By convention, the prediction target is called **y**. So the code we need to save the house prices melbourne data is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.Price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing \"Features\"\n",
    "\n",
    "The columns that are inputted into our model are called ```features```. In our case, these would be columns used to determine the home price. \n",
    "Sometimes, we will use all columns to except the target as features. Other times we will be better off with fewer features\n",
    "\n",
    "For starters we will use only few features. \n",
    "\n",
    "We will select multiple features by providing a list of column names inside brackets. Each item in the list will be a string (with quotes).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "melbourne_features = ['Rooms','Bathroom','Landsize','Lattitude','Longtitude']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By Convention, this data is called **X**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[melbourne_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets review the data we will be using to predict house prices using:\n",
    "- ```describe```\n",
    "- ```head```\n",
    "- ```info```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Bathroom</th>\n",
       "      <th>Landsize</th>\n",
       "      <th>Lattitude</th>\n",
       "      <th>Longtitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>13580.000000</td>\n",
       "      <td>13580.000000</td>\n",
       "      <td>13580.000000</td>\n",
       "      <td>13580.000000</td>\n",
       "      <td>13580.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>2.937997</td>\n",
       "      <td>1.534242</td>\n",
       "      <td>558.416127</td>\n",
       "      <td>-37.809203</td>\n",
       "      <td>144.995216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.955748</td>\n",
       "      <td>0.691712</td>\n",
       "      <td>3990.669241</td>\n",
       "      <td>0.079260</td>\n",
       "      <td>0.103916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-38.182550</td>\n",
       "      <td>144.431810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>-37.856822</td>\n",
       "      <td>144.929600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>440.000000</td>\n",
       "      <td>-37.802355</td>\n",
       "      <td>145.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>651.000000</td>\n",
       "      <td>-37.756400</td>\n",
       "      <td>145.058305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>433014.000000</td>\n",
       "      <td>-37.408530</td>\n",
       "      <td>145.526350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Rooms      Bathroom       Landsize     Lattitude    Longtitude\n",
       "count  13580.000000  13580.000000   13580.000000  13580.000000  13580.000000\n",
       "mean       2.937997      1.534242     558.416127    -37.809203    144.995216\n",
       "std        0.955748      0.691712    3990.669241      0.079260      0.103916\n",
       "min        1.000000      0.000000       0.000000    -38.182550    144.431810\n",
       "25%        2.000000      1.000000     177.000000    -37.856822    144.929600\n",
       "50%        3.000000      1.000000     440.000000    -37.802355    145.000100\n",
       "75%        3.000000      2.000000     651.000000    -37.756400    145.058305\n",
       "max       10.000000      8.000000  433014.000000    -37.408530    145.526350"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Bathroom</th>\n",
       "      <th>Landsize</th>\n",
       "      <th>Lattitude</th>\n",
       "      <th>Longtitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>-37.7996</td>\n",
       "      <td>144.9984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>-37.8079</td>\n",
       "      <td>144.9934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>-37.8093</td>\n",
       "      <td>144.9944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>-37.7969</td>\n",
       "      <td>144.9969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>-37.8072</td>\n",
       "      <td>144.9941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rooms  Bathroom  Landsize  Lattitude  Longtitude\n",
       "0      2       1.0     202.0   -37.7996    144.9984\n",
       "1      2       1.0     156.0   -37.8079    144.9934\n",
       "2      3       2.0     134.0   -37.8093    144.9944\n",
       "3      3       2.0      94.0   -37.7969    144.9969\n",
       "4      4       1.0     120.0   -37.8072    144.9941"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13580 entries, 0 to 13579\n",
      "Data columns (total 5 columns):\n",
      "Rooms         13580 non-null int64\n",
      "Bathroom      13580 non-null float64\n",
      "Landsize      13580 non-null float64\n",
      "Lattitude     13580 non-null float64\n",
      "Longtitude    13580 non-null float64\n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 530.6 KB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Model\n",
    "\n",
    "For this course we will be using **scikit-learn** library to create our models. Sci-kit learn is easily the most popular library for modeling the types of data typically stored in DataFrames, when using scikit learn the steps, to build model are:\n",
    "- **Define**: What type of model will it be? A decision Tree or some other model.\n",
    "- **Fit**: Capture patterns from provided data. *This is the heart of modeling*.\n",
    "- **Predict**: What it says\n",
    "- **Evaluate**: Determine how accurate our models prediction are.\n",
    "\n",
    "Lets look a quick example of using a decision Tree model with sci-kit learn and gitting it with features and target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
       "                      max_features=None, max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                      random_state=1, splitter='best')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Define the model. Sepcify a number for random_state to ensure the same results each run.\n",
    "model = DecisionTreeRegressor(random_state = 1)\n",
    "\n",
    "# Fit model\n",
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that is all there is to training a simple model.\n",
    "\n",
    "Many machine learning models allow some randomness in model training. Specifying a number for ```random_state``` ensures to get the same result in each run. *This is considered a good practice.*\n",
    "\n",
    "So now  we have a fitted model that we can use to make predictions\n",
    "\n",
    "Remember that in practice we'll want to make prediction for new houses coming on the market rather than the houses we already have prices for. However, we'll make prediction for the first few rows of the training data to see how the predict function works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions for the following 5 houses: \n",
      "   Rooms  Bathroom  Landsize  Lattitude  Longtitude\n",
      "0      2       1.0     202.0   -37.7996    144.9984\n",
      "1      2       1.0     156.0   -37.8079    144.9934\n",
      "2      3       2.0     134.0   -37.8093    144.9944\n",
      "3      3       2.0      94.0   -37.7969    144.9969\n",
      "4      4       1.0     120.0   -37.8072    144.9941\n",
      "The predictions are \n",
      "[1480000. 1035000. 1465000.  850000. 1600000.]\n"
     ]
    }
   ],
   "source": [
    "print('Making predictions for the following 5 houses: ')\n",
    "print(X.head())\n",
    "print('The predictions are ')\n",
    "print(model.predict(X.head()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we built a model, but we don't really know how good it is. Next we will use model validation to measure the quality of our model. Measuing model quality is the key to iteratively improving your models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Model Validation\n",
    "\n",
    "*Evaluate every model you build*\n",
    "\n",
    "In most applications the relevant meaure of model quality is its predictive accuracy. **In other words, will the model's predictions be close to what actually errors**.\n",
    "\n",
    "Many people make a huge mistake when measuring predictive accuracy. They make predictions with their training data and compare those predictions to the target values in the training data.\n",
    "We'll see the problem with this approach and how to solve it in a moment **but how do we do this**\n",
    "\n",
    "First we need to summarize the model quality in an understandable way. If we compare predicted and actual home values for 10,000 houses, we'll likely find a mix of good and bad predictions. But looking through a list of 10,00 predicted and actual values would be pointless. Therefore we have to condense it in a single metric.\n",
    "\n",
    "### Metrics\n",
    "\n",
    "There are many metrics but for this course we will focus on a few basic ones.\n",
    "**Mean Absolute Error** (MAE)\n",
    "Lets start with the last word *error*\n",
    "\n",
    "The prediction error for each house is:\n",
    "```error = actual - predicted```\n",
    "\n",
    "Therefore, if a house costs ```$150,000``` an you predicted it would cost ```$100,000``` the error is $50,000\n",
    "\n",
    "With the MAE metric, we take the asbolute value of each error. This converts each error to a positive number. We then take the average of these absolute errors. This our measure of model quality. In plain English, it can be stated as:\n",
    "\n",
    "*On average, our predictions are off by about X*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate MAE, we first need a model. That is built in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
       "                      max_features=None, max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                      random_state=None, splitter='best')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Loading Code Hidden Here\n",
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "file_path = 'data/melb_data.csv'\n",
    "melbourne_data = pd.read_csv(file_path) \n",
    "\n",
    "# Filter rows with missing price values\n",
    "filtered_melbourne_data = melbourne_data.dropna(axis=0)\n",
    "\n",
    "# Choose target and features\n",
    "y = filtered_melbourne_data.Price\n",
    "melbourne_features = ['Rooms', 'Bathroom', 'Landsize', 'BuildingArea', \n",
    "                        'YearBuilt', 'Lattitude', 'Longtitude']\n",
    "X = filtered_melbourne_data[melbourne_features]\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Define model\n",
    "melbourne_model = DecisionTreeRegressor()\n",
    "\n",
    "# Fit model\n",
    "melbourne_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What you are looking at above is usually what it takes to get a machine learning model trained. But it won't be a good model. So lets calculate the mean absolute error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "434.71594577146544"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "predicted_home_prices = melbourne_model.predict(X)\n",
    "mean_absolute_error(y,predicted_home_prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Problem with \"In-Sample\" Scores\n",
    "\n",
    "The measure we just computed can be called an *in-sample* score. We use a single 'sample' of houses for both building the model and evaluating it. Here's why this is bad.\n",
    "\n",
    "Imagine that, in the large estate market, door color is unrelated to home price.\n",
    "\n",
    "However in the sample of data we used to build the model, all homes with green doors were very expensive. The model's job is to find patterns that predict home prices, so it will see this pattern and it will always predict high prices for homes with green doors.\n",
    "\n",
    "Since this pattern was derived from the training data, the model will appear accurate in the training data.\n",
    "\n",
    "But if this pattern doesn't hold when the model sees new data, the model would be very inaccurate when used in practice.\n",
    "\n",
    "Since models' practical value come from making predictions on new data, we measure performance on data that wasn't used to build the model. The most straightforward way to do this is to exclude some data from the model-building process, and then use those to test the model's accuracy on data it hasn't seen before. This data is called validation data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scikit-learn library has a function ```train_test_split``` to break up the data into two pieces. We'll use some of that data as training data to fit the model, and we'll use the other data as validation data to calculate ```mean_absolute_error```.\n",
    "\n",
    "Here is the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262778.21885087155\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data into training and validation data, for both features and target\n",
    "# The split is based on a random number generator. Supplying a numeric value to\n",
    "# the random_state argument guarantees we get the same split every time we\n",
    "# run this script.\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state = 0)\n",
    "# Define model\n",
    "melbourne_model = DecisionTreeRegressor()\n",
    "# Fit model\n",
    "melbourne_model.fit(train_X, train_y)\n",
    "\n",
    "# get predicted prices on validation data\n",
    "val_predictions = melbourne_model.predict(val_X)\n",
    "print(mean_absolute_error(val_y, val_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation\n",
    "\n",
    "Your mean absolute error for the in-sample data was about 500 dollars. Out-of-sample it is more than 250,000 dollars.\n",
    "\n",
    "This is the difference between a model that is almost exactly right, and one that is unusable for most practical purposes. As a point of reference, the average home value in the validation data is 1.1 million dollars. So the error in new data is about a quarter of the average home value.\n",
    "\n",
    "There are many ways to improve this model, such as experimenting to find better features or different model types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Underfitting/Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end of this step, you will understand the concepts of underfitting and overfitting, and you will be able to apply these ideas to make your models more accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimenting With Different Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have a reliable way to measure model accuracy, you can experiment with alternative models and see which gives the best predictions. But what alternatives do you have for models?\n",
    "\n",
    "You can see in scikit-learn's documentation that the decision tree model has many options (more than you'll want or need for a long time). The most important options determine the tree's depth. Recall from the first lesson in this micro-course that a tree's depth is a measure of how many splits it makes before coming to a prediction. This is a relatively shallow tree\n",
    "\n",
    "![Decision Tree 3](images/DecisionTree-3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, it's not uncommon for a tree to have 10 splits between the top level (all houses) and a leaf. As the tree gets deeper, the dataset gets sliced up into leaves with fewer houses. If a tree only had 1 split, it divides the data into 2 groups. If each group is split again, we would get 4 groups of houses. Splitting each of those again would create 8 groups. If we keep doubling the number of groups by adding more splits at each level, we'll have  210  groups of houses by the time we get to the 10th level. That's 1024 leaves.\n",
    "\n",
    "When we divide the houses amongst many leaves, we also have fewer houses in each leaf. Leaves with very few houses will make predictions that are quite close to those homes' actual values, but they may make very unreliable predictions for new data (because each prediction is based on only a few houses).\n",
    "\n",
    "This is a phenomenon called **overfitting**, where a model matches the training data almost perfectly, but does poorly in validation and other new data. On the flip side, if we make our tree very shallow, it doesn't divide up the houses into very distinct groups.\n",
    "\n",
    "At an extreme, if a tree divides houses into only 2 or 4, each group still has a wide variety of houses. Resulting predictions may be far off for most houses, even in the training data (and it will be bad in validation too for the same reason). When a model fails to capture important distinctions and patterns in the data, so it performs poorly even in training data, that is called **underfitting**.\n",
    "\n",
    "Since we care about accuracy on new data, which we estimate from our validation data, we want to find the sweet spot between underfitting and overfitting. Visually, we want the low point of the (red) validation curve in\n",
    "\n",
    "![over/under](images/over-under-fit.png)\n",
    "\n",
    "\n",
    "## Example \n",
    "There are a few alternatives for controlling the tree depth, and many allow for some routes through the tree to have greater depth than other routes. But the max_leaf_nodes argument provides a very sensible way to control overfitting vs underfitting. The more leaves we allow the model to make, the more we move from the underfitting area in the above graph to the overfitting area.\n",
    "\n",
    "We can use a utility function to help compare MAE scores from different values for max_leaf_nodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "def get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y):\n",
    "    model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)\n",
    "    model.fit(train_X, train_y)\n",
    "    preds_val = model.predict(val_X)\n",
    "    mae = mean_absolute_error(val_y, preds_val)\n",
    "    return(mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is loaded into train_X, val_X, train_y and val_y using the code you've already seen (and which you've already written)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loading Code Runs At This Point\n",
    "import pandas as pd\n",
    "    \n",
    "# Load data\n",
    "file_path = 'data/melb_data.csv'\n",
    "melbourne_data = pd.read_csv(file_path) \n",
    "# Filter rows with missing values\n",
    "filtered_melbourne_data = melbourne_data.dropna(axis=0)\n",
    "# Choose target and features\n",
    "y = filtered_melbourne_data.Price\n",
    "melbourne_features = ['Rooms', 'Bathroom', 'Landsize', 'BuildingArea', \n",
    "                        'YearBuilt', 'Lattitude', 'Longtitude']\n",
    "X = filtered_melbourne_data[melbourne_features]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data into training and validation data, for both features and target\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y,random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use a for-loop to compare the accuracy of models built with different values for max_leaf_nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max leaf nodes: 5  \t\t Mean Absolute Error:  347380\n",
      "Max leaf nodes: 50  \t\t Mean Absolute Error:  258171\n",
      "Max leaf nodes: 500  \t\t Mean Absolute Error:  243495\n",
      "Max leaf nodes: 5000  \t\t Mean Absolute Error:  254983\n"
     ]
    }
   ],
   "source": [
    "# compare MAE with differing values of max_leaf_nodes\n",
    "for max_leaf_nodes in [5, 50, 500, 5000]:\n",
    "    my_mae = get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y)\n",
    "    print(\"Max leaf nodes: %d  \\t\\t Mean Absolute Error:  %d\" %(max_leaf_nodes, my_mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical-Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0 Load the Data\n",
    "\n",
    "Read the Iowa data file into a Pandas DataFrame called ```home_data```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-4-80dc9e96f11e>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-80dc9e96f11e>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    iowa_fil_url =\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# url of file to read\n",
    "iowa_file_url = # INSERT CODE HERE\n",
    "\n",
    "# fill in the line bellow to read the data\n",
    "iowa_data = _______ # INSERT CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0 Review the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print a description of the data\n",
    "______ # INSERT CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the average lot size (rounded to nearest integer)?\n",
    "avg_lot_size = ____ # INSERT CODE HERE\n",
    "\n",
    "# As of today, how old is the newest home (current year - the date in which it was built)\n",
    "newest_home_age = ____ # INSERT CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Think About Your Data\n",
    "\n",
    "EXAMPLE:\n",
    "*The newest house in your data isn't that new.  A few potential explanations for this:\n",
    "1. They haven't built new houses where this data was collected.\n",
    "1. The data was collected a long time ago. Houses built after the data publication wouldn't show up.\n",
    "If the reason is explanation #1 above, does that affect your trust in the model you build with this data? What about if it is reason #2?\n",
    "How could you dig into the data to see which explanation is more plausible?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting Data for Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0 Specify Prediction Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the list of columns in the dataset to find the name of the prediction target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can also print the ```head``` if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = # INSERT CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.0 Create X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you will create a DataFrame called `X` holding the predictive features.\n",
    "\n",
    "Since you want only some columns from the original data, you'll first create a list with the names of the columns you want in `X`.\n",
    "\n",
    "You'll use just the following columns in the list (you can copy and paste the whole list to save some typing, though you'll still need to add quotes):\n",
    "    * LotArea\n",
    "    * YearBuilt\n",
    "    * 1stFlrSF\n",
    "    * 2ndFlrSF\n",
    "    * FullBath\n",
    "    * BedroomAbvGr\n",
    "    * TotRmsAbvGrd\n",
    "\n",
    "After you've created that list of features, use it to create the DataFrame that you'll use to fit the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the list of features below\n",
    "feature_names = ___ # INSERT CODE HERE\n",
    "\n",
    "# Select data corresponding to features in feature_names\n",
    "X = ____ # INSERT CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review data\n",
    "# print description or statistics from X\n",
    "print(X.describe())\n",
    "\n",
    "# print the top few lines\n",
    "print(X.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.0 Specify and Fit Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a DecisionTreeRegressor and save it iowa_model. Ensure you've done the relevant import from sklearn to run this command.\n",
    "\n",
    "Then fit the model you just created using the data in X and y that you saved above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from _ import _ # INSERT CODE HERE\n",
    "#specify the model. \n",
    "\n",
    "#For model reproducibility, set a numeric value for random_state when specifying the model\n",
    "iowa_model = ____  # INSERT CODE HERE\n",
    "\n",
    "# Fit the model\n",
    "iowa_model.________ # INSERT CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.0 - Make Predictions\n",
    "Make predictions with the model's `predict` command using `X` as the data. Save the results to a variable called `predictions`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = ____\n",
    "\n",
    "print(\"First in-sample predictions:\", iowa_model.predict(X.head()))\n",
    "print(\"Actual target values for those homes:\", y.head().tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Think About Your Results\n",
    "\n",
    "Use the head method to compare the top few predictions to the actual home values (in y) for those same homes. Anything surprising?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's natural to ask how accurate the model's predictions will be and how you can improve that. That will be you're next step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.0 Split Your Data\n",
    "Use the `train_test_split` function to split up your data.\n",
    "\n",
    "Give it the argument `random_state=1` so the `check` functions know what to expect when verifying your code.\n",
    "\n",
    "Recall, your features are loaded in the DataFrame **X** and your target is loaded in **y**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the train_test_split function and uncomment\n",
    " from _ import _\n",
    "\n",
    "# fill in and uncomment\n",
    " train_X, val_X, train_y, val_y = ____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.0 Specify and Fit the Model\n",
    "Create a `DecisionTreeRegressor` model and fit it to the relevant data.\n",
    "Set `random_state` to 1 again when creating the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You imported DecisionTreeRegressor in 6.0 So, no need to\n",
    "# import it again\n",
    "\n",
    "# Specify the model\n",
    "iowa_model = ____\n",
    "\n",
    "# Fit iowa_model with the training data.\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.0 Make Predictions with Validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict with all validation observations\n",
    "val_predictions = ____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Inspect your predictions and actual values from validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the top few validation predictions\n",
    "print(____)\n",
    "# print the top few actual prices from validation data\n",
    "print(____)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you notice that is different from what you saw with in-sample predictions (which are printed after the top code cell in this page).\n",
    "\n",
    "Do you remember why validation predictions differ from in-sample (or training) predictions? This is an important idea from the last lesson."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.0 Calculate the Mean Absolute Error in Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "val_mae = ____\n",
    "\n",
    "# uncomment following line to see the validation_mae\n",
    "#print(val_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is that MAE good? There isn't a general rule for what values are good that applies across applications. But you'll see how to use (and improve) this number in the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You could write the function get_mae yourself. For now, we'll supply it. This is the same function you read about in the previous lesson. Just run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y):\n",
    "    model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)\n",
    "    model.fit(train_X, train_y)\n",
    "    preds_val = model.predict(val_X)\n",
    "    mae = mean_absolute_error(val_y, preds_val)\n",
    "    return(mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.0 Compare Different Tree Sizes\n",
    "Write a loop that tries the following values for *max_leaf_nodes* from a set of possible values.\n",
    "\n",
    "Call the *get_mae* function on each value of max_leaf_nodes. Store the output in some way that allows you to select the value of `max_leaf_nodes` that gives the most accurate model on your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_max_leaf_nodes = [5, 25, 50, 100, 250, 500]\n",
    "# Write loop to find the ideal tree size from candidate_max_leaf_nodes\n",
    "_\n",
    "\n",
    "# Store the best value of max_leaf_nodes (it will be either 5, 25, 50, 100, 250 or 500)\n",
    "best_tree_size = ____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.0 Fit Model Using All Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You know the best tree size. If you were going to deploy this model in practice, you would make it even more accurate by using all of the data and keeping that tree size. That is, you don't need to hold out the validation data now that you've made all your modeling decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in argument to make optimal size and uncomment\n",
    "final_model = DecisionTreeRegressor(____)\n",
    "\n",
    "# fit the final model and uncomment the next two lines\n",
    "final_model.fit(____, ____)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You've tuned this model and improved your results. But we are still using Decision Tree models, which are not very sophisticated by modern machine learning standards. In the next step you will learn to use Random Forests to improve your models even more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References:\n",
    "- [How Models Work](https://www.kaggle.com/dansbecker/how-models-work)\n",
    "- [Data Science from Scratch](https://www.amazon.com/Data-Science-Scratch-Principles-Python/dp/149190142X)\n",
    "- [Dataset Collections](https://shsulibraryguides.org/c.php?g=86808&p=2724093)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
